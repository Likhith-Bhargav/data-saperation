{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/nb.csv\")\n",
        "\n",
        "# Separate the features and the target variable\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "class NaiveBayes:\n",
        "    def __init__(self):\n",
        "        self.prior = {}\n",
        "        self.cond_prob = {}\n",
        "    \n",
        "    def fit(self, X_train, y_train):\n",
        "        # Calculate the prior probability of each class\n",
        "        self.prior[\"benign\"] = np.sum(y_train == \"B\") / len(y_train)\n",
        "        self.prior[\"malignant\"] = np.sum(y_train == \"M\") / len(y_train)\n",
        "        \n",
        "        # Calculate the conditional probability of each feature given to each class\n",
        "        for label in [\"benign\", \"malignant\"]:\n",
        "            label_indices = np.where(y_train == label)[0]\n",
        "            label_features = X_train.iloc[label_indices, :]\n",
        "            self.cond_prob[label] = {}\n",
        "            for feature in label_features.columns:\n",
        "                unique_vals, counts = np.unique(label_features[feature], return_counts=True)\n",
        "                prob_dict = dict(zip(unique_vals, counts/np.sum(counts)))\n",
        "                self.cond_prob[label][feature] = prob_dict\n",
        "    \n",
        "    def predict(self, X_test):\n",
        "        # Predict the class of a given instance using the Naive Bayes algorithm\n",
        "        predictions = []\n",
        "        for i in range(len(X_test)):\n",
        "            x = X_test.iloc[i, :]\n",
        "            benign_prob = self.prior[\"benign\"]\n",
        "            malignant_prob = self.prior[\"malignant\"]\n",
        "            for feature in X_test.columns:\n",
        "                if x[feature] in self.cond_prob[\"benign\"][feature]:\n",
        "                    benign_prob *= self.cond_prob[\"benign\"][feature][x[feature]]\n",
        "                else:\n",
        "                    benign_prob *= 0\n",
        "                if x[feature] in self.cond_prob[\"malignant\"][feature]:\n",
        "                    malignant_prob *= self.cond_prob[\"malignant\"][feature][x[feature]]\n",
        "                else:\n",
        "                    malignant_prob *= 0\n",
        "            if benign_prob > malignant_prob:\n",
        "                predictions.append(\"B\")\n",
        "            else:\n",
        "                predictions.append(\"M\")\n",
        "        return predictions\n",
        "    \n",
        "    def score(self, X_test, y_test):\n",
        "        # Calculate the accuracy of your Naive Bayes classifier on the testing set\n",
        "        y_pred = self.predict(X_test)\n",
        "        accuracy = np.mean(y_pred == y_test)\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, pos_label='M')\n",
        "        recall = recall_score(y_test, y_pred, pos_label='M')\n",
        "        f1 = f1_score(y_test, y_pred, pos_label='M')\n",
        "        return accuracy, cm, precision, recall, f1\n",
        "\n",
        "# Train the model\n",
        "nb = NaiveBayes()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Test the model\n",
        "accuracy, cm, precision, recall, f1 = nb.score(X_test, y_test)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"confusion matrix\", cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AKd0iEhi_Gt",
        "outputId": "f504cdf8-7fee-4995-de6e-82e373fed562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7474382157926461\n",
            "Precision: 0.7474382157926461\n",
            "Recall: 1.0\n",
            "F1 Score: 0.8554674025526042\n",
            "confusion matrix [[   0 2514]\n",
            " [   0 7440]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/nb.csv\")\n",
        "\n",
        "# Separate the features and the target variable\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]\n",
        "\n",
        "# Initialize lists to store evaluation metrics for each split\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "# Make 10 different train-test splits\n",
        "for i in range(10):\n",
        "    print(\"Split\", i+1)\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=i)\n",
        "    \n",
        "    # Train the model\n",
        "    nb = NaiveBayes()\n",
        "    nb.fit(X_train, y_train)\n",
        "\n",
        "    # Test the model\n",
        "    accuracy, cm, precision, recall, f1 = nb.score(X_test, y_test)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1)\n",
        "    \n",
        "    # Store the evaluation metrics for this split\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate the mean and variance of the evaluation metrics over the 10 splits\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "var_accuracy = np.var(accuracies)\n",
        "mean_precision = np.mean(precisions)\n",
        "var_precision = np.var(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "var_recall = np.var(recalls)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "var_f1 = np.var(f1_scores)\n",
        "\n",
        "# Print the mean and variance of the evaluation metrics\n",
        "print(\"Mean accuracy:\", mean_accuracy)\n",
        "print(\"Variance of accuracy:\", var_accuracy)\n",
        "print(\"Mean precision:\", mean_precision)\n",
        "print(\"Variance of precision:\", var_precision)\n",
        "print(\"Mean recall:\", mean_recall)\n",
        "print(\"Variance of recall:\", var_recall)\n",
        "print(\"Mean F1 score:\", mean_f1)\n",
        "print(\"Variance of F1 score:\", var_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD3eh_nSHmA5",
        "outputId": "c948ae17-840c-4d7c-b087-1feb8c8b3eb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split 1\n",
            "Accuracy: 0.7512557765722323\n",
            "Precision: 0.7512557765722323\n",
            "Recall: 1.0\n",
            "F1 Score: 0.8579623680587426\n",
            "Split 2\n",
            "Accuracy: 0.7507534659433394\n",
            "Precision: 0.7507534659433394\n",
            "Recall: 1.0\n",
            "F1 Score: 0.8576347047684627\n",
            "Split 3\n",
            "Accuracy: 0.7470363672895318\n",
            "Precision: 0.7470363672895318\n",
            "Recall: 1.0\n",
            "F1 Score: 0.8552041403105233\n",
            "Split 4\n",
            "Accuracy: 0.746031746031746\n",
            "Precision: 0.746031746031746\n",
            "Recall: 1.0\n",
            "F1 Score: 0.8545454545454546\n",
            "Split 5\n",
            "Accuracy: 0.7497488446855536\n",
            "Precision: 0.7497488446855536\n",
            "Recall: 1.0\n",
            "F1 Score: 0.8569788138026067\n",
            "Split 6\n",
            "Accuracy: 0.7462326702833032\n",
            "Precision: 0.7462326702833032\n",
            "Recall: 1.0\n",
            "F1 Score: 0.8546772523299966\n",
            "Split 7\n",
            "Accuracy: 0.7526622463331324\n",
            "Precision: 0.7526622463331324\n",
            "Recall: 1.0\n",
            "F1 Score: 0.8588788260919408\n",
            "Split 8\n",
            "Accuracy: 0.7450271247739603\n",
            "Precision: 0.7450271247739603\n",
            "Recall: 1.0\n",
            "F1 Score: 0.8538860103626943\n",
            "Split 9\n",
            "Accuracy: 0.7488446855535463\n",
            "Precision: 0.7488446855535463\n",
            "Recall: 1.0\n",
            "F1 Score: 0.8563878676470588\n",
            "Split 10\n",
            "Accuracy: 0.750853928069118\n",
            "Precision: 0.750853928069118\n",
            "Recall: 1.0\n",
            "F1 Score: 0.8577002524672941\n",
            "Mean accuracy: 0.7488446855535462\n",
            "Variance of accuracy: 6.146416978014464e-06\n",
            "Mean precision: 0.7488446855535462\n",
            "Variance of precision: 6.146416978014464e-06\n",
            "Mean recall: 1.0\n",
            "Variance of recall: 0.0\n",
            "Mean F1 score: 0.8563855690384774\n",
            "Variance of F1 score: 2.629123784547862e-06\n"
          ]
        }
      ]
    }
  ]
}