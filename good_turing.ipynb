{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hrHHSvdSF1p",
        "outputId": "0e3c50a0-0a7b-4b6c-e658-c5f356059a88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7537978863936592\n",
            "Precision: 0.7537978863936592\n",
            "Recall: 1.0\n",
            "F1 Score: 0.8596177384427078\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/nb.csv\")\n",
        "\n",
        "# Separate the features and the target variable\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "class NaiveBayes:\n",
        "    def __init__(self, alpha=1):\n",
        "        self.alpha = alpha\n",
        "        self.prior = {}\n",
        "        self.cond_prob = {}\n",
        "    \n",
        "    def fit(self, X_train, y_train):\n",
        "        # Calculate the prior probability of each class\n",
        "        self.prior[\"benign\"] = np.sum(y_train == \"B\") / len(y_train)\n",
        "        self.prior[\"malignant\"] = np.sum(y_train == \"M\") / len(y_train)\n",
        "        \n",
        "        # Calculate the conditional probability of each feature given to each class\n",
        "        for label in [\"benign\", \"malignant\"]:\n",
        "            label_indices = np.where(y_train == label)[0]\n",
        "            label_features = X_train.iloc[label_indices, :]\n",
        "            self.cond_prob[label] = {}\n",
        "            for feature in label_features.columns:\n",
        "                unique_vals, counts = np.unique(label_features[feature], return_counts=True)\n",
        "                # Apply Good-Turing smoothing\n",
        "                gt_counts = self.good_turing_smoothing(counts)\n",
        "                prob_dict = dict(zip(unique_vals, gt_counts/np.sum(gt_counts)))\n",
        "                self.cond_prob[label][feature] = prob_dict\n",
        "    \n",
        "    def predict(self, X_test):\n",
        "        # Predict the class of a given instance using the Naive Bayes algorithm\n",
        "        predictions = []\n",
        "        for i in range(len(X_test)):\n",
        "            x = X_test.iloc[i, :]\n",
        "            benign_prob = self.prior[\"benign\"]\n",
        "            malignant_prob = self.prior[\"malignant\"]\n",
        "            for feature in X_test.columns:\n",
        "                if x[feature] in self.cond_prob[\"benign\"][feature]:\n",
        "                    benign_prob *= self.cond_prob[\"benign\"][feature][x[feature]]\n",
        "                else:\n",
        "                    benign_prob *= self.alpha / (len(self.cond_prob[\"benign\"][feature]) + self.alpha * len(X_test[feature].unique()))\n",
        "                if x[feature] in self.cond_prob[\"malignant\"][feature]:\n",
        "                    malignant_prob *= self.cond_prob[\"malignant\"][feature][x[feature]]\n",
        "                else:\n",
        "                    malignant_prob *= self.alpha / (len(self.cond_prob[\"malignant\"][feature]) + self.alpha * len(X_test[feature].unique()))\n",
        "            if benign_prob > malignant_prob:\n",
        "                predictions.append(\"B\")\n",
        "            else:\n",
        "                predictions.append(\"M\")\n",
        "        return predictions\n",
        "    \n",
        "    def good_turing_smoothing(self, counts):\n",
        "        # Apply Good-Turing smoothing to the frequency counts\n",
        "        unique_counts = np.unique(counts)\n",
        "        smoothed_counts = np.zeros_like(counts)\n",
        "        for i in range(len(counts)):\n",
        "            if counts[i] == 0:\n",
        "                smoothed_counts[i] = self.alpha / len(counts)\n",
        "            elif counts[i] in unique_counts:\n",
        "                index = np.where(unique_counts == counts[i])[0][0]\n",
        "                smoothed_counts[i] = (index+1) * (unique_counts[index+1] / unique_counts[index])\n",
        "            else:\n",
        "                smoothed_counts[i] = counts[i]\n",
        "        return smoothed_counts\n",
        "    \n",
        "    def score(self, X_test, y_test):\n",
        "        # Calculate the accuracy of your Naive Bayes classifier on the testing set\n",
        "        y_pred = self.predict(X_test)\n",
        "        accuracy = np.mean(y_pred == y_test)\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, pos_label='M')\n",
        "        recall = recall_score(y_test, y_pred, pos_label='M')\n",
        "        f1 = f1_score(y_test, y_pred, pos_label='M')\n",
        "        return accuracy, cm, precision, recall, f1\n",
        "\n",
        "# Train the model\n",
        "nb = NaiveBayes()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Test the model\n",
        "accuracy, cm, precision, recall, f1 = nb.score(X_test, y_test)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ]
    }
  ]
}